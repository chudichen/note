#### 数据倾斜产生的原因和现象

* 对于大数据来说，数据量大并不可怕，可怕的是数据倾斜
* 数据（key）分布不均匀 =》 造成数据大量集中在某个点上，造成数据热点问题
* shuffle：join on （条件）、 group by（条件）

##### 现象：

1. 大部分的task都非常快的完成，只有少数task处理得非常慢

* Spark: UI对应的job/stage/task
* 有些场景下虽然task处理的很慢，但是最终还是可以完成任务的。

2. 有些场景下，虽然极少数的task处理得非常慢，但是还是可以处理完成的。还有一些是平时运行的没问题，某天突然发生了OOM，作业很大可能就挂了：

* 手动的去干预，去处理（low）
* 遇到数据倾斜的场景应该要具备自适应的能力（high）

#### MapReduce种的Shuffle

* 在shuffle的时候，必须将各个节点相同的key拉取到某一个节点进行task的处理，比如：join、group by。如果某个key对应的数据量非常大，那么该key做处理的时候，必然会产生数据倾斜。
* 查询MapReduce的Shuffle过程

#### Spark中的Shuffle

* 窄依赖：父RDD的partition至多被子RDD的某个partition使用一次
* 宽依赖：一个父RDD的partition会被子RDD的partition多次使用
  * 遇到shuffle，原来的stage就会被拆分，查询spark shuffle原理。
  * 窄依赖实现容错很简单（pipline方式），宽依赖复杂（shuffle是复杂操作）。

#### 数据倾斜的场景

* 核心原因在于key的分布不均匀，需要把key打散
* group阶段把key打散
* join阶段把key打散

